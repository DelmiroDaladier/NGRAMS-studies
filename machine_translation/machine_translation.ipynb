{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machine_translation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPE9RU0eQCDvjhVlYw1d21k"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BNCfpKBOzJs"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from string import digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras import Model\n",
        "from keras.layers import Dropout, Input, Embedding, LSTM, Dense"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5-YJO7WO_5R",
        "outputId": "4d56a5ee-16ae-4c49-8c1a-b1b5b0ac9ecd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "en_dataset = pd.read_csv('small_vocab_en.csv', header=None, error_bad_lines=False, sep='/n', nrows=15000)\n",
        "fr_dataset = pd.read_csv('small_vocab_fr.csv', header=None, error_bad_lines=False, sep='/n', nrows=15000)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlUJ3tU2SPuD"
      },
      "source": [
        "en_dataset.rename({0:'text'}, inplace=True, axis=1)\n",
        "fr_dataset.rename({0:'text'}, inplace=True, axis=1)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDMYP1UyPtWb"
      },
      "source": [
        "remove_digits =  str.maketrans('', '', digits) \n",
        "\n",
        "en_dataset['text'] = en_dataset['text'].apply(lambda x: x.lower())\n",
        "fr_dataset['text'] = fr_dataset['text'].apply(lambda x: x.lower())\n",
        "\n",
        "en_dataset['text'] = en_dataset['text'].apply(lambda x: re.sub(\"[^\\w\\s]\", \"\",x))\n",
        "fr_dataset['text'] = fr_dataset['text'].apply(lambda x: re.sub(\"[^\\w\\s]\", \"\",x))\n",
        "\n",
        "en_dataset['text'] = en_dataset['text'].apply(lambda x: x.translate(remove_digits))\n",
        "fr_dataset['text'] = fr_dataset['text'].apply(lambda x: x.translate(remove_digits))\n",
        "\n",
        "en_dataset['text'] = en_dataset['text'].apply(lambda x: x.strip())\n",
        "fr_dataset['text'] = fr_dataset['text'].apply(lambda x: x.strip())\n",
        "\n",
        "en_dataset['text'] = en_dataset['text'].apply(lambda x: '<SOS> ' + x + ' <EOS>')\n",
        "fr_dataset['text'] = fr_dataset['text'].apply(lambda x: '<SOS> ' + x + ' <EOS>')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzcOZByfSi4F"
      },
      "source": [
        "word_to_index_en = {}\n",
        "index_to_word_en = {}\n",
        "word_index = 0\n",
        "for sentence in en_dataset['text'].values:\n",
        "  for word in sentence.split():\n",
        "    if word not in word_to_index_en.keys():\n",
        "      word_to_index_en[word] = word_index\n",
        "      index_to_word_en[word_index] = word\n",
        "      word_index += 1\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JYKmA85aGOn"
      },
      "source": [
        "max_len_en = max([len(sentence) for sentence in en_dataset['text']])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2we4E70sYxdX"
      },
      "source": [
        "word_to_index_fr = {}\n",
        "index_to_word_fr = {}\n",
        "word_index = 0\n",
        "for sentence in fr_dataset['text'].values:\n",
        "  for word in sentence.split():\n",
        "    if word not in word_to_index_fr.keys():\n",
        "      word_to_index_fr[word] = word_index\n",
        "      index_to_word_fr[word_index] = word\n",
        "      word_index += 1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPF2CLkUageN"
      },
      "source": [
        "max_len_fr = max([len(sentence) for sentence in fr_dataset['text']])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boDApHWacCAv"
      },
      "source": [
        "num_encoder_tokens = len(word_to_index_en.keys())\n",
        "num_decoder_tokens = len(word_to_index_fr.keys())"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CcK8LS_ZupI"
      },
      "source": [
        "X = en_dataset['text'].values\n",
        "Y = fr_dataset['text'].values\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0n7Zoi6doi3"
      },
      "source": [
        "\n",
        "encoder_input = np.zeros((X_train.shape[0], max_len_en, num_encoder_tokens), dtype='float32')\n",
        "decoder_input = np.zeros((X_train.shape[0], max_len_fr, num_decoder_tokens), dtype='float32')\n",
        "decoder_target = np.zeros((X_train.shape[0], max_len_fr, num_decoder_tokens), dtype='float32')\n",
        "\n",
        "for j, (input_sentence, target_sentence) in enumerate(zip(X_train, Y_train)):\n",
        "    for pos, word in enumerate(input_sentence.split()):\n",
        "      encoder_input[j, pos, word_to_index_en[word]] = 1.0\n",
        "    encoder_input[j, pos+1, word_to_index_en['<EOS>']] = 1.0\n",
        "\n",
        "    for pos, word in enumerate(target_sentence.split()):\n",
        "      decoder_input[j, pos, word_to_index_fr[word]] = 1.0\n",
        "\n",
        "      if pos > 0:\n",
        "        decoder_target[j, pos-1, word_to_index_fr[word]] = 1.0\n",
        "\n",
        "    decoder_input[j, pos, word_to_index_en['<EOS>']] = 1.0\n",
        "    decoder_target[j, pos:, word_to_index_en['<EOS>']] = 1.0"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsdPKZtJhvYV"
      },
      "source": [
        "latent_dim=64\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation=\"softmax\")\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OA7PAzhpADf"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApGzXQJkpYSc",
        "outputId": "5f38ee61-3c0c-405f-d894-3753e0f81bcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(\n",
        "    optimizer=\"rmsprop\", loss='categorical_crossentropy', metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    [encoder_input, decoder_input],\n",
        "    decoder_target,\n",
        "    batch_size=64,\n",
        "    epochs=100,\n",
        "    validation_split=0.2,\n",
        ")\n",
        "\n",
        "# Save model\n",
        "model.save(\"s2s\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "169/169 [==============================] - 69s 410ms/step - loss: 0.8402 - accuracy: 0.8888 - val_loss: 0.4501 - val_accuracy: 0.8982\n",
            "Epoch 2/100\n",
            "169/169 [==============================] - 69s 406ms/step - loss: 0.4092 - accuracy: 0.9124 - val_loss: 0.3606 - val_accuracy: 0.9205\n",
            "Epoch 3/100\n",
            "169/169 [==============================] - 68s 400ms/step - loss: 0.3155 - accuracy: 0.9264 - val_loss: 0.2747 - val_accuracy: 0.9311\n",
            "Epoch 4/100\n",
            "169/169 [==============================] - 68s 403ms/step - loss: 0.2476 - accuracy: 0.9375 - val_loss: 0.2219 - val_accuracy: 0.9420\n",
            "Epoch 5/100\n",
            "169/169 [==============================] - 68s 402ms/step - loss: 0.2049 - accuracy: 0.9446 - val_loss: 0.1862 - val_accuracy: 0.9467\n",
            "Epoch 6/100\n",
            "169/169 [==============================] - 68s 400ms/step - loss: 0.1765 - accuracy: 0.9481 - val_loss: 0.1654 - val_accuracy: 0.9497\n",
            "Epoch 7/100\n",
            "169/169 [==============================] - 68s 400ms/step - loss: 0.1599 - accuracy: 0.9509 - val_loss: 0.1522 - val_accuracy: 0.9518\n",
            "Epoch 8/100\n",
            "169/169 [==============================] - 68s 405ms/step - loss: 0.1490 - accuracy: 0.9526 - val_loss: 0.1430 - val_accuracy: 0.9537\n",
            "Epoch 9/100\n",
            "169/169 [==============================] - 68s 402ms/step - loss: 0.1415 - accuracy: 0.9537 - val_loss: 0.1401 - val_accuracy: 0.9542\n",
            "Epoch 10/100\n",
            "169/169 [==============================] - 68s 404ms/step - loss: 0.1361 - accuracy: 0.9547 - val_loss: 0.1351 - val_accuracy: 0.9541\n",
            "Epoch 11/100\n",
            "169/169 [==============================] - 69s 406ms/step - loss: 0.1328 - accuracy: 0.9555 - val_loss: 0.1285 - val_accuracy: 0.9561\n",
            "Epoch 12/100\n",
            "169/169 [==============================] - 68s 404ms/step - loss: 0.1271 - accuracy: 0.9569 - val_loss: 0.1237 - val_accuracy: 0.9575\n",
            "Epoch 13/100\n",
            "169/169 [==============================] - 69s 405ms/step - loss: 0.1230 - accuracy: 0.9580 - val_loss: 0.1206 - val_accuracy: 0.9587\n",
            "Epoch 14/100\n",
            "169/169 [==============================] - 68s 402ms/step - loss: 0.1197 - accuracy: 0.9590 - val_loss: 0.1200 - val_accuracy: 0.9584\n",
            "Epoch 15/100\n",
            "169/169 [==============================] - 68s 403ms/step - loss: 0.1168 - accuracy: 0.9601 - val_loss: 0.1147 - val_accuracy: 0.9611\n",
            "Epoch 16/100\n",
            "169/169 [==============================] - 68s 402ms/step - loss: 0.1139 - accuracy: 0.9610 - val_loss: 0.1135 - val_accuracy: 0.9611\n",
            "Epoch 17/100\n",
            "169/169 [==============================] - 68s 405ms/step - loss: 0.1147 - accuracy: 0.9611 - val_loss: 0.1179 - val_accuracy: 0.9597\n",
            "Epoch 18/100\n",
            "169/169 [==============================] - 69s 406ms/step - loss: 0.1122 - accuracy: 0.9616 - val_loss: 0.1172 - val_accuracy: 0.9607\n",
            "Epoch 19/100\n",
            "169/169 [==============================] - 69s 406ms/step - loss: 0.1298 - accuracy: 0.9561 - val_loss: 0.1324 - val_accuracy: 0.9541\n",
            "Epoch 20/100\n",
            "169/169 [==============================] - 69s 407ms/step - loss: 0.1257 - accuracy: 0.9563 - val_loss: 0.1228 - val_accuracy: 0.9577\n",
            "Epoch 21/100\n",
            "169/169 [==============================] - 68s 403ms/step - loss: 0.1226 - accuracy: 0.9569 - val_loss: 0.1239 - val_accuracy: 0.9560\n",
            "Epoch 22/100\n",
            "169/169 [==============================] - 69s 405ms/step - loss: 0.1236 - accuracy: 0.9568 - val_loss: 0.1297 - val_accuracy: 0.9545\n",
            "Epoch 23/100\n",
            "169/169 [==============================] - 68s 405ms/step - loss: 0.1195 - accuracy: 0.9576 - val_loss: 0.1194 - val_accuracy: 0.9579\n",
            "Epoch 24/100\n",
            "169/169 [==============================] - 69s 407ms/step - loss: 0.1187 - accuracy: 0.9577 - val_loss: 0.1182 - val_accuracy: 0.9588\n",
            "Epoch 25/100\n",
            "169/169 [==============================] - 68s 403ms/step - loss: 0.1173 - accuracy: 0.9581 - val_loss: 0.1189 - val_accuracy: 0.9576\n",
            "Epoch 26/100\n",
            "169/169 [==============================] - 68s 402ms/step - loss: 0.1158 - accuracy: 0.9584 - val_loss: 0.1151 - val_accuracy: 0.9593\n",
            "Epoch 27/100\n",
            "169/169 [==============================] - 70s 411ms/step - loss: 0.1140 - accuracy: 0.9591 - val_loss: 0.1144 - val_accuracy: 0.9589\n",
            "Epoch 28/100\n",
            "169/169 [==============================] - 69s 409ms/step - loss: 0.1131 - accuracy: 0.9593 - val_loss: 0.1146 - val_accuracy: 0.9588\n",
            "Epoch 29/100\n",
            "169/169 [==============================] - 68s 402ms/step - loss: 0.1120 - accuracy: 0.9598 - val_loss: 0.1113 - val_accuracy: 0.9603\n",
            "Epoch 30/100\n",
            "169/169 [==============================] - 68s 402ms/step - loss: 0.1109 - accuracy: 0.9602 - val_loss: 0.1110 - val_accuracy: 0.9602\n",
            "Epoch 31/100\n",
            "169/169 [==============================] - 68s 404ms/step - loss: 0.1102 - accuracy: 0.9603 - val_loss: 0.1102 - val_accuracy: 0.9605\n",
            "Epoch 32/100\n",
            "169/169 [==============================] - 68s 402ms/step - loss: 0.1093 - accuracy: 0.9606 - val_loss: 0.1102 - val_accuracy: 0.9602\n",
            "Epoch 33/100\n",
            "169/169 [==============================] - 68s 404ms/step - loss: 0.1088 - accuracy: 0.9608 - val_loss: 0.1094 - val_accuracy: 0.9607\n",
            "Epoch 34/100\n",
            "169/169 [==============================] - 69s 407ms/step - loss: 0.1082 - accuracy: 0.9611 - val_loss: 0.1115 - val_accuracy: 0.9603\n",
            "Epoch 35/100\n",
            "169/169 [==============================] - 69s 406ms/step - loss: 0.1076 - accuracy: 0.9613 - val_loss: 0.1110 - val_accuracy: 0.9602\n",
            "Epoch 36/100\n",
            "169/169 [==============================] - ETA: 0s - loss: 0.1069 - accuracy: 0.9615"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2BjphAwrEPZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNNeQTYKrJsZ"
      },
      "source": [
        "y, x = next(datagen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qqf1eCbs1P2",
        "outputId": "8016bff8-4be6-4062-be6f-33f6df58ce1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[  0.,  22.,   3., ...,   0.,   0.,   0.],\n",
              "        [  0.,  40.,   3., ...,   0.,   0.,   0.],\n",
              "        [  0.,  98.,   3., ...,   0.,   0.,   0.],\n",
              "        ...,\n",
              "        [  0.,  14.,  68., ...,   0.,   0.,   0.],\n",
              "        [  0., 187., 115., ...,   0.,   0.,   0.],\n",
              "        [  0.,  72.,   3., ...,   0.,   0.,   0.]], dtype=float32),\n",
              " array([[  0.,  75.,   3., ...,   0.,   0.,   0.],\n",
              "        [  0.,  43.,   3., ...,   0.,   0.,   0.],\n",
              "        [  0., 116., 154., ...,   0.,   0.,   0.],\n",
              "        ...,\n",
              "        [  0.,  34.,  72., ...,   0.,   0.,   0.],\n",
              "        [  0., 285., 144., ...,   0.,   0.,   0.],\n",
              "        [  0.,  79.,   3., ...,   0.,   0.,   0.]], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo-Hl9RsujwT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}